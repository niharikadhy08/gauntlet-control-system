# ğŸ§¤ Gauntlet Control System

A **computer visionâ€“based hand gesture control system** inspired by the **Infinity Gauntlet** from Marvelâ€™s *Avengers*.

This project uses **MediaPipe**, **OpenCV**, and **Pygame** to detect hand gestures in real time using a webcam and map them to **Infinity Stones, Gauntlet states, images, and sound effects** â€” creating an interactive, demo-ready experience.

---

## Concept & Inspiration

In the Marvel universe, the Infinity Gauntlet derives its power from six Infinity Stones.
Similarly, in this project:

* **Finger-count gestures (1â€“6 fingers)** represent the six Infinity Stones
* **Gauntlet states** are triggered using specific multi-hand gestures
* A **single fist** represents the infamous snap (half the universe disappears)
* **Two fists** represent a stable universe
* **Two open palms** represent the Gauntlet with all stones collected

---

## Gesture Mapping Logic

| Gesture                | Action                                      |
| ---------------------- | ------------------------------------------- |
| 1 fist (0 fingers)     | ğŸ’¥ Half the universe disappears             |
| 2 fists                | ğŸŒ Full population (stable universe)        |
| 1 finger               | ğŸŸ¦ Space Stone                              |
| 2 fingers              | ğŸŸ¨ Mind Stone                               |
| 3 fingers              | ğŸ”´ Reality Stone                            |
| 4 fingers              | ğŸŸª Power Stone                              |
| 5 fingers              | ğŸŸ© Time Stone                               |
| 6 fingers (both hands) | ğŸŸ  Soul Stone                               |
| 2 open palms           | ğŸ§¤ Infinity Gauntlet (all stones collected) |

Each gesture:

* Displays a **themed image**
* Plays a **corresponding sound effect**
* Is **locked for a few seconds** to prevent flickering or false triggers

---

## Features

* ğŸ–ï¸ Real-time hand and finger detection
* ğŸ¯ Accurate gesture classification using landmark-based logic
* ğŸ§  On-screen HUD showing hands detected, finger count, and active gesture
* ğŸ–¼ï¸ Separate result window for visual feedback
* ğŸ”Š Sound effects synced with gestures
* â±ï¸ Gesture locking for stable interaction
* ğŸ§± Clean, modular architecture (`hand_detector`, `gesture_logic`, `main`)

---

## Tech Stack

* **Python 3.10+**
* **OpenCV** â€“ video capture and rendering
* **MediaPipe Tasks** â€“ hand landmark detection
* **Pygame** â€“ audio playback
* **Webcam**

---

## Project Structure

```
gauntlet-control-system/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # Application entry point
â”‚   â”œâ”€â”€ hand_detector.py     # MediaPipe hand detection wrapper
â”‚   â””â”€â”€ gesture_logic.py     # Finger state & gesture logic
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ pics/                # Gesture images
â”‚   â””â”€â”€ sounds/              # Gesture sound effects
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ hand_landmarker.task
â”‚
â”œâ”€â”€ venv/
â””â”€â”€ README.md
```

---

## How to Run

### 1ï¸âƒ£ Activate virtual environment

```
venv\Scripts\activate
```

### 2ï¸âƒ£ Install dependencies

```
python -m pip install opencv-python mediapipe pygame
```

### 3ï¸âƒ£ Run the project

```
python src/main.py
```

Press **ESC** to exit the application.

---

## Demo Usage Tips

* For **accurate finger detection**, keep the **back side of your palm facing the camera** (palm facing away)
* Hold gestures steady for **1â€“2 seconds**
* Ensure **good lighting** for best landmark detection accuracy
